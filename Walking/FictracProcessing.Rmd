---
title: "Fictrac Batch Processing"
author: "James Foster"
output:
  prettydoc::html_pretty:
    theme: cayman
    highlight: github
---
## Details ---------------------------------------------------------------

> **AUTHOR**	
> 
  James Foster               2022 01 12


> **MODIFIED**
>
  James Foster            2022 03 25


> **DESCRIPTION** 
>
  Loads all `.dat` files saved by `FicTrac` and organises data into
  speed and angle. These are saved as compressed `.csv` files and 
  which are then combined into a single `.txt` file.


> **INPUTS** 
>
  A `.dat` csv file with 23 columns specified in : 
  https://github.com/rjdmoore/fictrac/blob/master/doc/data_header.txt             
  The user should specify analysis details in the ['User Input'](#user) section.


> **OUTPUTS** 
>
  Results table (.csv) saved in the same place as the data.


> **CHANGES** 
>
>    * Load FictracDat_Functions.R
>    * Speed up with parallel
>    * Speed up with data.table
>    * Read all files directly to single tab sep file
>    * Nicer looking HTML with ```prettydoc```
>    * Averaging across phases
>    * Inline graphics with ```include_graphics```
>    * Benchmarking (see ```Benchmark_FictracProcessing.R```)
>    * [Clean up method](#cleanup)


> **REFERENCES** 
>
  Moore RJD, Taylor GJ, Paulk AC, Pearson T, van Swinderen B, 
  Srinivasan MV (2014). 
  FicTrac: a visual method for tracking spherical motion and 
  generating fictive animal paths. 
  *Journal of neuroscience methods* 225, 106â€“19. 
  https://doi.org/10.1016/j.jneumeth.2014.01.010                                  
  https://github.com/rjdmoore/fictrac


> **USAGE**  
>
  Fill out [User Input](#user) and then run all sections sequentially.



```{r Set up HTML, include=FALSE}
if(!is.null(getOption("knitr.in.progress")))
{ # only used during "knitting"
knitr::opts_chunk$set(echo = TRUE, 
                      tidy.opts = list(width.cutoff = 35, 
                                       tidy = TRUE))
}
```

## Input variables
Find out everything R needs to know to process the `.dat` files.

### - Clean up{#cleanup}
If this script, or any of its functions, has been run on this data before, you might consider deleting the output files to ensure all data are processed in the same way.

This can be done using `FT_delete_processed()` from `FictracDat_Functions.R`.

### - User input{#user}
Note that the size of the averaging window an have a big effect on time-averaged parameters: too short and it is biased by small fluctuations, too large and it  may not reflect structures in the data at shorter temporal scales (see: https://en.wikipedia.org/wiki/Aliasing).


I recommend using both `data.table` & `parallel` to speed up processing.
`data.table` is a tool for rapid reading, writing and calculations with large text datasets, and can reduce time taken by approx. *10%*.
`parallel` allows processes to be split between different CPUs to be run separately, in parallel.


Adding `parallel` to `data.table` can reduce time by a further *55%*.

On 20220310 a test on AG Pfeiffer laptop 5 (`wbz2084`: Intel(R) Core(TM) i7-10510U CPU @ 1.80GHz   2.30 GHz) with 28 files took 6min 33sec.

```{r User input}
ball_radius = 25#mm
exper_leng = 2 #minutes
cond_leng = 1 #minutes
av_window = 5.0#number of seconds to smooth over for averaging
phase_window = 10.0#number of seconds to average over for each phase
csv_sep_load = ','#Is the csv comma separated or semicolon separated? For tab sep, use "\t"
use_dt = TRUE # whether or not to use data.table for reading, converting & writing
use_par = TRUE # whether or not to use parallel processing
```


### - Load packages
Load the packages required to run the analysis. If these packages are not already installed on your machine, you will need to install them before running this section.
( `install.packages(...)` or select `Tools>Install packages` in the Rstudio menu)
```{r Load packages, echo=TRUE, message = FALSE, warning = FALSE}
require(circular)#for handing angles
require(bspec)#for spectrum/frequency analysis
if(use_dt)
  {
  require(R.utils) # sometimes missing from older Rstudio 
  require(data.table)
  }#for fast data handling
if(use_par){require(parallel)}#for parallel processing
```

### - Set up the parallel cluster
If the user input indicated that they would like to use parallel processing, 
`R` will open a "cluster" of processors to use.
It detects how many processors are available and uses all except one
(leaving some power for other processes happening on the computer).
In combination with `data.table`, this utilises most of the computer's CPU.
```{r Set up parallel processing, echo=TRUE}
if(use_par)
  {
  clt = parallel::makeCluster(spec = parallel::detectCores() - 1,
                              type="SOCK")
  }
```


### - Load functions
Load the special functions for processing `FicTrac` output.


These should be in a file called `FictracDat_Functions.R` downloaded in the same folder as this script, from GitHub (which is the first place `R` will look).

```{r Search for functions file, echo=TRUE}
fun_file = "FictracDat_Functions.R"
fun_path = tryCatch(expr = #Search in the folder containing this script
                      {file.path(dirname(sys.frame(1)$ofile), fun_file)},
                    error = function(e){fun_file}
)
```

Ask the user if the functions file cannot be found
```{r Ask the user}
if(!file.exists(fun_path))#If not found, ask the user
{
  msg = paste0('Please select "',fun_file,'"')
  # ask user to find data
  if( Sys.info()[['sysname']] == 'Windows' ){#choose.files is only available on Windows
    message('\n\n',msg,'\n\n')
    Sys.sleep(0.5)#goes too fast for the user to see the message on some computers
    fun_path = choose.files(#For some reason not possible in the "root" user
                          default = file.path(
                                      gsub(pattern = '\\\\', 
                                           replacement = '/', 
                                           x = Sys.getenv('USERPROFILE')),#user
                                      'Documents'),
                          caption = msg
                          )
}else
{
    message('\n\n',msg,'\n\n')
    Sys.sleep(0.5)#goes too fast for the user to see the message on some computers
    fun_path = file.choose(new = FALSE)
  }
}
```

Load the file containing all necessary functions.
```{r Read in the relevant functions}
source(file = fun_path, 
       encoding = 'UTF-8')
```


####    - Load into the parallel cluster
If using parallel processing, add these functions to the parallel cluster
```{r Add functions to parallel cluster}
 parallel::clusterExport(cl = clt,
                         varlist = 
                           c('MAmeanang',
                             'MAmeanvec',
                             'MAturnspeed',
                             'MAsmoothturn',
                             'Mod360.180',
                             'mean.circular',
                             'rho.circular',
                             'circular',
                             'deg',
                             'rad'),
                         envir = environment()#needs to be reminded to use current environment, NOT global environment
  )
```

## Search for the files
The user should select a folder containing all `.dat` files saved by `FicTrac`.


This folder should have the structure:


  Inside the **selected folder** =
      folder named for the **date** (yyyymmdd)
      
      
  Inside each **date folder** = 
      folder with the **animal's name** (any string)
      
      
  Inside each **animal folder** = 
      folder with the **condition name** (any string; should be the same as the equivalent for other animals)
      
      
  Inside each **condition folder** = 
      `.dat` files saved by `FicTrac` for that condition and animal, on that day.
```{r Find the folder, echo=TRUE}
if(interactive())#for knitting, it is not possible to ask the user
{path_folder = FT_select_folder(file_type = 'Fictrac experiment')}else
{path_folder = "C:\\Users\\jaf54iq\\Documents\\AllTestdata\\Pascal"}
```

Search for any `.dat` files in the data folder and sub-folders.
```{r Find the files, echo=TRUE}
path_files = list.files(path = path_folder,
                        pattern = '.dat$',
                        recursive = T
)
```

## Process all files
Open each `.dat` file, perform some additional calculations 
(convert to real-world units of distance, calculate moving averages across time)
and then save as a compressed `.csv` file with headers in the same folder. 
These files can then be opened for plotting (`R` or `Excel`)
```{r Echo ".dat" file names and set the path, echo=TRUE}
message(length(path_files),
        ' files found:\n', 
        paste0(path_files,'\n'), 
        '\nProcessing files.',
        '\n------------------------------------------')
path_input = file.path(
                        path_folder,
                        path_files)
```

Run processing as a loop. This step may take a *very* long time.
```{r Process ".dat" files, echo=TRUE}
path_csv = lapply(
                  X = path_input,
                  FUN = FT_read_write,
                  ball_radius = ball_radius,#mm
                  av_window = av_window,#seconds to smooth over for averaging
                  csv_sep_load = csv_sep_load,#Is the csv comma or semicolon separated?
                  speedup_parallel = use_par, #Use parallel to speed up calculations
                  speedup_data.table = FALSE, #Don't use data.table inside the loop
                  compress_csv = TRUE, #Compress to ".gz" to save space?
                  verbose = FALSE, #tell the user what's going on?
                  clust = clt
                  )
names(path_csv) = path_input
```

Check that all files were processed
```{r Compare input and output file list}
if(all(!is.na(path_csv)))
{
  message('\n','Files processed','\n')
}else
{
  warning(path_input[is.na(path_csv)], '\nnot processed!')
}
```

## Combine all files
Read in each of the saved `.csv` files in each folder, 
and combine the data into a single table including the name of the original file,
the condition, the animal and the date. 
This is then saved as a `.txt` file with the same headers as the `.csv` file, 
plus headers for condition, bumblebee name, date and `.dat` file.
This may take a long time, and use a lot of memory.
```{r Combine across all trials, echo=TRUE}
message('Combining data from all trials.',
        '\n------------------------------------------')
path_txt = FT_combine_folders(
            path_folder = path_folder,
            file_type = '_proc.csv.gz',#N.B. currently only for this type
            speedup_parallel = use_dt, #Use the parallel package to speed up calculations
            speedup_data.table = use_par, #Use the data.table package to speed up reading and writing
            compress_txt = TRUE, #Compress to ".gz" to save space?
            verbose = TRUE, #Tell the user what is going on
            recursive = TRUE,   #Search in sub folders                          
            clust = clt
            )
```

Check that combining was successful.
```{r Check combined output file}
if(all(!is.na(path_txt)))
{
  message('\n','Files combined','\n')
}else
{
  warning('\nCombining failed!')
}
```

## Average across files
Read in the saved `.txt` file, and, in each track,
average across specified time-windows (phases). 
This data is saved as an uncompressed `.csv`,
containing a single table with most of the same headers as the `.txt` file.


Check for a path to the `.txt` file.
If the user started here, they will need to select it.
```{r Look for the txt file, echo=TRUE}
if(!exists('path_txt'))
{
  if(!exists('path_folder'))#if folder is missing too
  {path_folder = FT_select_folder(file_type = '_proc.txt.gz')}
  if(interactive())#in an interactive session
  {path_txt = FT_select_file(file_type = '_proc.txt.gz')}else
  { #in knitr
    path_txt = file.path(path_folder,
                        list.files(path = path_folder,
                                   pattern = '_proc.txt.gz',
                                   recursive = TRUE)
  )
  message('Processed txt file found:\n',
          path_txt)
  }
  
}

```

Average each track across phases.
This may take a long time.
```{r Average across phases, echo=TRUE}
message('Averaging data across phases.',
        '\n------------------------------------------')
path_av = FT_TimeAverage_all(
            path_file = path_txt,
            experiment_length = exper_leng, #minutes
            med_window = 10.0,#seconds phase length
            speedup_parallel = use_par, #Use parallel processing
            speedup_data.table = use_dt, #Use data.table to read & write
            verbose = TRUE, #Tell the user what is going on
            show_plot = FALSE, #Tell the user what is going on
            show_csv = FALSE, #Open the output table after saving
            clust = clt
            )
```

Check that averaging was successful.
```{r Check averaging output file}
if(all(!is.na(path_av)))
{
  message('\n','Files averaged','\n')
}else
{
  warning('\nAveraging failed!')
}
```

## Plot data
Open each processed `.csv` file, and plot as a PDF.

_**N.B**_ Any PDF files already existing within the folder will be deleted at this stage to avoid conflicts.

Remove any pre-existing PDFs the user might have generated to avoid conflicts.
```{r Find and delete PDFs in the folder, echo=TRUE}
#Find the PDFs
pre_pdfs = list.files(path = path_folder,
                      pattern = '.pdf$',#ends in PDF
                      recursive = TRUE)
if(length(pre_pdfs))
{
  warning(
          ' deleting existing PDFs in the folder','\n', 
          '\n------------------------------------------')
}
#delete each one
deleted_pdfs = lapply(X = file.path(path_folder,
                                   pre_pdfs
                                   ),
                     FUN = file.remove
                     )
names(deleted_pdfs) = basename(pre_pdfs)
if(length(deleted_pdfs))
{
  message('Deleted:\n',
          paste0(names(deleted_pdfs[unlist(deleted_pdfs)]),'\n')
          )
}
```

Check for paths to the processed `.csv` files.
If the user started here, they will need to select the folder
```{r Look for the csv file, echo=TRUE}
if(!exists('path_csv'))
{
  if(!exists('path_folder'))#in an interactive session
  {path_folder = FT_select_folder(file_type = "_proc.csv.gz")}
  path_csv = file.path(path_folder,
                      list.files(path = path_folder,
                                 pattern = '_proc.csv.gz$',
                                 recursive = TRUE)
                      )
  message(length(path_csv), 
          ' processed files found:\n',
                  paste0(basename(path_csv),'\n')
          )
}

```

Plot all tracks individually as a PDF in the same folder.
This may take a very long time.

```{r Plot ".csv" files, echo=TRUE}
#Plot all
message('Plotting ',
        length(path_csv),
        ' files:\n', 
        paste0(lapply(X=path_csv, FUN=basename),'\n'), 
        '\nPlotting files.',
        '\n------------------------------------------')
path_pdf = if(use_par) #FT_plot_track doesn't use parallel processing,
            { # so can perhaps be run in parallel
              parLapply(
                  cl = clt,
                  X = path_csv,
                  fun = FT_plot_track,#N.B. not "FUN" in  parLapply()
                  show_plot = FALSE, #don't open the plot immediately
                  av_window = 5.0, #seconds to smooth over for averaging
                  plt_speed_max = 200, #y axis maximum speed
                  save_type = 'pdf',#Save as PDF or PNG
                  speedup_parallel = FALSE, #Not used
                  speedup_data.table = use_dt, #Speed up reading and writing
                  verbose = TRUE #Tell the user what is going on
                  )
            }else
            {
              lapply(
                  X = path_csv,
                  FUN = FT_plot_track,
                  show_plot = FALSE, #don't open the plot immediately
                  av_window = 5.0, #seconds to smooth over for averaging
                  plt_speed_max = 200, #y axis maximum speed
                  save_type = 'pdf',#Save as PDF or PNG
                  speedup_parallel = use_par, #Use parallel processing
                  speedup_data.table = use_dt, #Speed up reading and writing
                  verbose = TRUE #Tell the user what is going on
                  )
            }
names(path_pdf) = path_csv
```

Check that plotting was successful.
```{r Check for plotted files}
  if(all(!is.na(path_pdf)))
{
  message('\n','Files plotted','\n')
}else
{
  warning(basename(path_csv[is.na(path_pdf)]), '\nnot plotted!')
}
```

Re-plot one example as a `PNG` that can be displayed in this file.

```{r Plot an example}
#select and plot an example
example_csv = file.path(path_csv[!is.na(path_pdf)][1]) #first converted file
example_png = FT_plot_track(
                path_file = example_csv,
                save_type = 'png',#Save as PDF or PNG
                show_plot = FALSE, #don't open the plot immediately
                plt_leg_cex = 1.5,#show a large legend
                av_window = av_window, #seconds to smooth over for averaging
                plt_speed_max = 200, #y axis maximum speed
                speedup_parallel = use_par, #Use parallel processing
                speedup_data.table = use_dt, #Speed up reading and writing
                verbose = TRUE, #Tell the user what is going on
                clust =clt
                )
knitr::include_graphics(path = example_png)
```

## Raster plot
To view all tracks in context, plot the summary statistics from each experiment aligned together as a heatmap. Individual trials are stacked and labelled along the y-axis, the x-axis shows time in the experiment.

Check for a path to the `.txt` file.
If the user started here, they will need to select it.
```{r Find txt file, echo=TRUE}
if(!exists('path_txt'))
{
  if(!exists('path_folder'))#if folder is missing too
  {path_folder = FT_select_folder(file_type = '_proc.txt.gz')}
  if(interactive())#in an interactive session
  {path_txt = FT_select_file(file_type = '_proc.txt.gz')}else
  { #in knitr
    path_txt = file.path(path_folder,
                        list.files(path = path_folder,
                                   pattern = '_proc.txt.gz',
                                   recursive = TRUE)
  )
  message('Processed txt file found:\n',
          path_txt)
  }
  
}

```


Save raster plots for all experiments.
This may take some time.
```{r Show all raw data as a Raster plot}
rast_plot = FT_raster_condition(
                        txt_file = path_txt,
                        experiment_length = exper_leng, #minutes
                        condition1_length = cond_leng, #minutes
                        av_window = av_window,#number of seconds to smooth over for averaging
                        save_type = "png",#
                        ranking = FALSE,#
                        crossval = FALSE, # TRUE, randomise the data to check the analysis
                        speedup_parallel = use_par, #Use the parallel package to speed up calculations
                        speedup_data.table = use_dt, #Use the data.table package to speed up reading and writing
                        verbose = TRUE, #Tell the user what is going on
                        show_plot = FALSE, #Tell the user what is going on
                        clust = clt                        )
```

Show all raster plots
```{r Raster plots, echo = FALSE}
knitr::include_graphics( as.character(rast_plot) )
```

## Stop the parallel cluster
Stop the parallel cluster, as it will not be used from this point onwards.

```{r Stop the parallel cluster}
if(use_par){parallel::stopCluster(clt)}
```

## Plot Averages
Make a boxplot summary of the median value in each `phase_window` across each experiment type.

Check for a path to the `_average.csv` file.
If the user started here, they will need to select it.
```{r Find _average.csv file, echo=TRUE}
if(!exists('path_av'))
{
  if(!exists('path_folder'))#if folder is missing too
  {path_folder = FT_select_folder(file_type = '_average.csv')}
  if(interactive())#in an interactive session
  {
    path_av = FT_select_file(file_type = '_average.csv')
  }else
  { #in knitr
    path_av = file.path(path_folder,
                        list.files(path = path_folder,
                                   pattern = '_average.csv',
                                   recursive = TRUE)
  )
  message('Processed csv file found:\n',
          basename(path_av)
          )
  }
  
}

```


Save boxplots for all experiments

```{r Plot averaged data for each phase}
av_plot = FT_plot_average(path_file = path_av,
                           experiment_length = exper_leng, #minutes
                           condition1_length = cond_leng, #minutes
                           av_window = av_window,#number of seconds to smooth over for averaging
                           med_window = phase_window,#number of seconds to combine across for each phase
                           save_type = "png",# "pdf",# 
                           crossval = FALSE, # TRUE, data were randomised to check the analysis
                           speedup_data.table = use_dt, #Use the data.table package to speed up reading and writing
                           verbose = TRUE, #Tell the user what is going on
                           show_plot = FALSE #Don't open plot immediately
)
```

Show all average plots

```{r Average plots, echo = FALSE}
  knitr::include_graphics( as.character(av_plot) )
```